{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    I have to say, Apple has by far the best custo...\n",
       "1    iOS 7 is so fricking smooth & beautiful!! #Tha...\n",
       "2                                        LOVE U @APPLE\n",
       "3    Thank you @apple, loving my new iPhone 5S!!!!!...\n",
       "4    .@apple has the best customer service. In and ...\n",
       "5    @apple ear pods are AMAZING! Best sound from i...\n",
       "6    Omg the iPhone 5S is so cool it can read your ...\n",
       "7              the iPhone 5c is so beautiful <3 @Apple\n",
       "8    #AttributeOwnership is exactly why @apple will...\n",
       "9    Just checked out the specs on the new iOS 7......\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df = pd.read_csv(r'./tweets.csv')\n",
    "tweets_df = tweets_df['Tweet'].astype('str')\n",
    "tweets_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stop_words = [\n",
    "    'some', 'like', 'think', 'wow', 'one', 'http', 'web', 'really',\n",
    "    'see', 'watch', 'apple', 'know', 'show', 'think', 'click', 'go', 'to', 'great',\n",
    "    'very', 'good', 'many', 'more', 'people', 'made', 'technology', 'tech',\n",
    "    'iphone', 'ipad', 'new', 'latest', 'phone', 'itunes', 'brand', 'ipod', 'iphones',\n",
    "    'io', 'get', 'buy', 'purchase', 'make', 'im', \"iam\", 'dont', 'cant', 'promoipodplayerpromo',\n",
    "    'ipodplayerpromo', 'player', 'itune']\n",
    "\n",
    "def pre_process_text(df, custom_stopwords):\n",
    "    translate_table = dict((ord(char), None) for char in string.punctuation)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words = stop_words.union(custom_stopwords)\n",
    "\n",
    "    corpus = []\n",
    "    for i, line in df.iteritems():\n",
    "        line = line.lower()\n",
    "        line = re.sub(r\"\\d+\", \"\", line)\n",
    "        line = line.translate(translate_table)\n",
    "        line = line.split()\n",
    "\n",
    "        # Lemmatizers reduces each word to its root/canonical form\n",
    "        lm = WordNetLemmatizer()\n",
    "        line = [lm.lemmatize(word) for word in line if not word in stop_words]\n",
    "        line = \" \".join(line)\n",
    "        corpus.append(line)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_score(sentence_series):\n",
    "    df_dict = {}\n",
    "    for i, response in df.iteritems():\n",
    "        sent_analyzer = SentimentIntensityAnalyzer()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7c2737f5cd3eb6a237b7123ce75c641d6f975db18b0c0702ad2055474d78171c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
