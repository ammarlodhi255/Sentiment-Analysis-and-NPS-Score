{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    I have to say, Apple has by far the best custo...\n",
       "1    iOS 7 is so fricking smooth & beautiful!! #Tha...\n",
       "2                                        LOVE U @APPLE\n",
       "3    Thank you @apple, loving my new iPhone 5S!!!!!...\n",
       "4    .@apple has the best customer service. In and ...\n",
       "5    @apple ear pods are AMAZING! Best sound from i...\n",
       "6    Omg the iPhone 5S is so cool it can read your ...\n",
       "7              the iPhone 5c is so beautiful <3 @Apple\n",
       "8    #AttributeOwnership is exactly why @apple will...\n",
       "9    Just checked out the specs on the new iOS 7......\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df = pd.read_csv(r'./tweets.csv')\n",
    "tweets_df = tweets_df['Tweet'].astype('str')\n",
    "tweets_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stop_words = [\n",
    "    'some', 'like', 'think', 'wow', 'one', 'http', 'web', 'really',\n",
    "    'see', 'watch', 'apple', 'know', 'show', 'think', 'click', 'go', 'to', 'great',\n",
    "    'very', 'good', 'many', 'more', 'people', 'made', 'technology', 'tech',\n",
    "    'iphone', 'ipad', 'new', 'latest', 'phone', 'itunes', 'brand', 'ipod', 'iphones',\n",
    "    'io', 'get', 'buy', 'purchase', 'make', 'im', \"iam\", 'dont', 'cant', 'promoipodplayerpromo',\n",
    "    'ipodplayerpromo', 'player', 'itune']\n",
    "\n",
    "def pre_process_text(df, custom_stopwords):\n",
    "    translate_table = dict((ord(char), None) for char in string.punctuation)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words = stop_words.union(custom_stopwords)\n",
    "\n",
    "    corpus = []\n",
    "    for i, line in df.iteritems():\n",
    "        line = line.lower()\n",
    "        line = re.sub(r\"\\d+\", \"\", line)\n",
    "        line = line.translate(translate_table)\n",
    "        line = line.split()\n",
    "\n",
    "        # Lemmatizers reduces each word to its root/canonical form\n",
    "        lm = WordNetLemmatizer()\n",
    "        line = [lm.lemmatize(word) for word in line if not word in stop_words]\n",
    "        line = \" \".join(line)\n",
    "        corpus.append(line)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_score(sentence_series):\n",
    "    df_dict = {}\n",
    "    for i, response in sentence_series.iteritems():\n",
    "        sent_analyzer = SentimentIntensityAnalyzer()\n",
    "        scores = sent_analyzer.polarity_scores(response)\n",
    "        df_dict[i] = scores\n",
    "    df = pd.DataFrame.from_dict(df_dict)\n",
    "    return df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       say far best customer care service ever receiv...\n",
       "1                 io fricking smooth beautiful thanxapple\n",
       "2                                                  love u\n",
       "3                     thank loving pictwittercomxmhjcupcb\n",
       "4                               best customer service min\n",
       "                              ...                        \n",
       "1176                                                freak\n",
       "1177            freaking picture tl annoyed freak twitter\n",
       "1178                                   freaking cow freak\n",
       "1179                             hate working going freak\n",
       "1180                   agounalakis thats nasty nasty brat\n",
       "Length: 1181, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_series = pd.Series(pre_process_text(tweets_df, new_stop_words))\n",
    "tweets_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_sentiment_score(tweets_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.8126</td>\n",
       "      <td>say far best customer care service ever receiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.6344</td>\n",
       "      <td>io fricking smooth beautiful thanxapple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>love u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.7506</td>\n",
       "      <td>thank loving pictwittercomxmhjcupcb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>best customer service min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.8402</td>\n",
       "      <td>ear pod amazing best sound inear headphone ive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>omg cool read finger print unlock purchase wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.5994</td>\n",
       "      <td>c beautiful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>attributeownership exactly always marketing ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>checked spec io say wait update bravo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   neg    neu    pos  compound  \\\n",
       "0  0.0  0.486  0.514    0.8126   \n",
       "1  0.0  0.489  0.511    0.6344   \n",
       "2  0.0  0.000  1.000    0.6369   \n",
       "3  0.0  0.135  0.865    0.7506   \n",
       "4  0.0  0.417  0.583    0.6369   \n",
       "5  0.0  0.467  0.533    0.8402   \n",
       "6  0.0  0.777  0.223    0.3182   \n",
       "7  0.0  0.000  1.000    0.5994   \n",
       "8  0.0  0.729  0.271    0.3818   \n",
       "9  0.0  1.000  0.000    0.0000   \n",
       "\n",
       "                                               Tweet  \n",
       "0  say far best customer care service ever receiv...  \n",
       "1            io fricking smooth beautiful thanxapple  \n",
       "2                                             love u  \n",
       "3                thank loving pictwittercomxmhjcupcb  \n",
       "4                          best customer service min  \n",
       "5  ear pod amazing best sound inear headphone ive...  \n",
       "6  omg cool read finger print unlock purchase wit...  \n",
       "7                                        c beautiful  \n",
       "8  attributeownership exactly always marketing ma...  \n",
       "9              checked spec io say wait update bravo  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tweet'] = tweets_series.iloc[:]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63      ibrooklynb loved iphonec better cuz name aweso...\n",
       "1033    nokia release amazing smartphones within year ...\n",
       "232     darnit lol donza mishiza natz samsungsa perfec...\n",
       "95      currently waiting review app hopefully asap th...\n",
       "13      interesting seem almost willing demise whats g...\n",
       "5       ear pod amazing best sound inear headphone ive...\n",
       "644       google laughing laughing left love chrome stink\n",
       "114     dear excellent ad submitted update please appr...\n",
       "92      excited introducing touchid biometric security...\n",
       "46      totally missed giving away iphoto imovie iwork...\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the most positive tweets\n",
    "df.sort_values(by='compound', ascending=False)['Tweet'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(0, 'ID', range(0, len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.8126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.6344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.6369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.7506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.6369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.8402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.3182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.5994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.3818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  neg    neu    pos  compound\n",
       "0   0  0.0  0.486  0.514    0.8126\n",
       "1   1  0.0  0.489  0.511    0.6344\n",
       "2   2  0.0  0.000  1.000    0.6369\n",
       "3   3  0.0  0.135  0.865    0.7506\n",
       "4   4  0.0  0.417  0.583    0.6369\n",
       "5   5  0.0  0.467  0.533    0.8402\n",
       "6   6  0.0  0.777  0.223    0.3182\n",
       "7   7  0.0  0.000  1.000    0.5994\n",
       "8   8  0.0  0.729  0.271    0.3818\n",
       "9   9  0.0  1.000  0.000    0.0000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group customers as either Promoters, Detractors, and Neutrals\n",
    "df_group = df.groupby(by='ID').mean()\n",
    "df_group.reset_index(inplace=True)\n",
    "df_group.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ID    neg    neu    pos  compound\n",
      "1135  1135  0.840  0.160  0.000   -0.9413\n",
      "1173  1173  0.714  0.153  0.133   -0.9246\n",
      "1124  1124  0.714  0.286  0.000   -0.9100\n",
      "1151  1151  0.914  0.086  0.000   -0.8910\n",
      "1038  1038  0.529  0.471  0.000   -0.8779\n",
      "------------------------------------------\n",
      "        ID    neg    neu    pos  compound\n",
      "46      46  0.121  0.389  0.490    0.8218\n",
      "114    114  0.000  0.449  0.551    0.8225\n",
      "92      92  0.000  0.455  0.545    0.8225\n",
      "644    644  0.166  0.184  0.650    0.8360\n",
      "5        5  0.000  0.467  0.533    0.8402\n",
      "13      13  0.000  0.462  0.538    0.8519\n",
      "95      95  0.000  0.359  0.641    0.8658\n",
      "232    232  0.000  0.452  0.548    0.8658\n",
      "1033  1033  0.000  0.466  0.534    0.8834\n",
      "63      63  0.000  0.223  0.777    0.9313\n"
     ]
    }
   ],
   "source": [
    "df_group.sort_values(by='compound', inplace=True)\n",
    "print(df_group.head())\n",
    "print('------------------------------------------')\n",
    "print(df_group.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "7c2737f5cd3eb6a237b7123ce75c641d6f975db18b0c0702ad2055474d78171c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
