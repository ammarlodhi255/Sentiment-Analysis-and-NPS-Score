{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Ammar\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    I have to say, Apple has by far the best custo...\n",
       "1    iOS 7 is so fricking smooth & beautiful!! #Tha...\n",
       "2                                        LOVE U @APPLE\n",
       "3    Thank you @apple, loving my new iPhone 5S!!!!!...\n",
       "4    .@apple has the best customer service. In and ...\n",
       "5    @apple ear pods are AMAZING! Best sound from i...\n",
       "6    Omg the iPhone 5S is so cool it can read your ...\n",
       "7              the iPhone 5c is so beautiful <3 @Apple\n",
       "8    #AttributeOwnership is exactly why @apple will...\n",
       "9    Just checked out the specs on the new iOS 7......\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df = pd.read_csv(r'./tweets.csv')\n",
    "tweets_df = tweets_df['Tweet'].astype('str')\n",
    "tweets_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stop_words = [\n",
    "    'some', 'like', 'think', 'wow', 'one', 'http', 'web', 'really',\n",
    "    'see', 'watch', 'apple', 'know', 'show', 'think', 'click', 'go', 'to', 'great',\n",
    "    'very', 'good', 'many', 'more', 'people', 'made', 'technology', 'tech',\n",
    "    'iphone', 'ipad', 'new', 'latest', 'phone', 'itunes', 'brand', 'ipod', 'iphones',\n",
    "    'io', 'get', 'buy', 'purchase', 'make', 'im', \"iam\", 'dont', 'cant', 'promoipodplayerpromo',\n",
    "    'ipodplayerpromo', 'player', 'itune']\n",
    "\n",
    "def pre_process_text(df, custom_stopwords):\n",
    "    translate_table = dict((ord(char), None) for char in string.punctuation)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words = stop_words.union(custom_stopwords)\n",
    "\n",
    "    corpus = []\n",
    "    for i, line in df.iteritems():\n",
    "        line = line.lower()\n",
    "        line = re.sub(r\"\\d+\", \"\", line)\n",
    "        line = line.translate(translate_table)\n",
    "        line = line.split()\n",
    "\n",
    "        # Lemmatizers reduces each word to its root/canonical form\n",
    "        lm = WordNetLemmatizer()\n",
    "        line = [lm.lemmatize(word) for word in line if not word in stop_words]\n",
    "        line = \" \".join(line)\n",
    "        corpus.append(line)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_score(sentence_series):\n",
    "    df_dict = {}\n",
    "    for i, response in sentence_series.iteritems():\n",
    "        sent_analyzer = SentimentIntensityAnalyzer()\n",
    "        scores = sent_analyzer.polarity_scores(response)\n",
    "        df_dict[i] = scores\n",
    "    df = pd.DataFrame.from_dict(df_dict)\n",
    "    return df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       say far best customer care service ever receiv...\n",
       "1                 io fricking smooth beautiful thanxapple\n",
       "2                                                  love u\n",
       "3                     thank loving pictwittercomxmhjcupcb\n",
       "4                               best customer service min\n",
       "                              ...                        \n",
       "1176                                                freak\n",
       "1177            freaking picture tl annoyed freak twitter\n",
       "1178                                   freaking cow freak\n",
       "1179                             hate working going freak\n",
       "1180                   agounalakis thats nasty nasty brat\n",
       "Length: 1181, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_series = pd.Series(pre_process_text(tweets_df, new_stop_words))\n",
    "tweets_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        neg    neu    pos  compound\n",
      "0     0.000  0.486  0.514    0.8126\n",
      "1     0.000  0.489  0.511    0.6344\n",
      "2     0.000  0.000  1.000    0.6369\n",
      "3     0.000  0.135  0.865    0.7506\n",
      "4     0.000  0.417  0.583    0.6369\n",
      "...     ...    ...    ...       ...\n",
      "1176  1.000  0.000  0.000   -0.4404\n",
      "1177  0.735  0.265  0.000   -0.8074\n",
      "1178  0.851  0.149  0.000   -0.6908\n",
      "1179  0.767  0.233  0.000   -0.7650\n",
      "1180  0.706  0.294  0.000   -0.8020\n",
      "\n",
      "[1181 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df = get_sentiment_score(tweets_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "7c2737f5cd3eb6a237b7123ce75c641d6f975db18b0c0702ad2055474d78171c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
